\newpage
\section{Анализ предметной области}
\label{sec:Background}

Open Journal System – это программное обеспечение, которое позволяет публиковать статьи и организовать рабочий процесс издательства. На ее основе разработаны многие порталы, работают институты, научные центры и журналы в разных странах мира (интерфейс OPS переведeн более чем на 30 языков). Платформа обладает модульной структурой и имеет возможность подключения плагинов. 

OJS может быть рассмотрена как электронная библиотека: программа обеспечивает доступ к контенту, поиск по нему (автора, ключевые слова, названия статей, год выпуска и так далее). 

Нахождение фиктивных аккаунтов в Open Journal System является темой данной работы. Для выбора наилучшего подхода к решению задач и достижения цели были прочитаны некоторые статьи на тему выявления <<фейков>> и их влияния на аккаунты реальных людей. Далее рассмотрены исследования, которые были использованы в ходе работы.

Авторы статьи~\cite{HassanAA23} раскрывают проблему поддельных страниц. Их количество растет вместе с увеличением числа активных пользователей. Поддельные профили на сайтах социальных сетей создают ненастоящие новости и распространяют нежелательные материалы, содержащие спам-ссылки. В этой статье приводится контролируемый алгоритм машинного обучения, называемый машиной опорных векторов (SVM), который используется вместе с методом случайного леса. Эту концепцию можно применить для идентификации большого количества учетных записей, которые невозможно проверить вручную. Данная модель сравнивается с другими методами идентификации, и результаты показывают, что предложенный авторами алгоритм работает с большей точностью. 

Статья~\cite{ElyusufiEK19} посвящена выявлению поддельных профилей в социальных сетях. Для их обнаружения было предложено множество алгоритмов и методов, и авторы этой работы оценивают точность использования дерева решений (DT) и наивного алгоритма Байеса (NB) для классификации профилей пользователей на поддельные и подлинные.

В работе~\cite{UppadaMVHS22} исследователи используют модель SENAD, которая определяет подлинность новостных статей, публикуемых в Twitter, на основе подлинности и предвзятости пользователей, которые взаимодействуют с этими статьями. Предлагаемая модель включает в себя идею оценки соотношения подписчиков, возраст аккаунта и т.д. Для анализа изображений предлагается использовать нейронную сеть (CredNN). Предложенная гибридная идея объединения ELA и Sent и анализа настроений помогает обнаруживать поддельные изображения с точностью около 76\%.
    
В исследовании~\cite{GurajalaWHM15} проведен анализ 62 миллионов общедоступных профилей пользователей Twitter, и разработана стратегия идентификации автоматически сгенерированных поддельных профилей. Используя алгоритм сопоставления шаблонов имен, анализ времени обновления твитов и даты создания профилей, были выявлены фиктивные учетные записи пользователей.

В статье~\cite{abs-2308-05353} описывается новый алгоритм под названием Preferred attachment k-class Classifier (PreAttacK) для обнаружения поддельных учетных записей в социальной сети. Авторы работы собирают некоторые из первых аналитических данных о том, как новые (поддельные и реальные) аккаунты пытаются завести друзей, ориентируясь на их первые запросы о дружбе после регистрации в социальной сети (Facebook). Исследователи используют эту модель для создания нового алгоритма PreAttacK. 

В работе~\cite{MohammadrezaeiS19} авторы представляют метод обнаружения, основанный на сходстве пользователей, с учетом их сетевых коммуникаций. На первом
этапе измеряются такие параметры, как общие соседи, ребра графа общих соседей, косинус и коэффициент подобия Жаккарда, которые вычисляются на основе матрицы смежности соответствующего графа социальной сети. На следующем шаге, чтобы уменьшить сложность данных, к каждой вычисленной матрице подобия применяется компонентный анализ для получения набора информативных признаков. Затем с помощью метода локтя выбирается набор высокоинформативных собственных векторов. Извлеченные функции используются для обучения алгоритма классификации. 

В статье~\cite{StolbovaGI21} представлено исследование поддельных аккаунтов в социальных сетях с использованием искусственной нейронной сети для их идентификации. Специально разработанное и внедренное приложение было использовано для выявления специфических особенностей поддельных аккаунтов и изучения принципов и причин их генерации. На основе изучения 500 реальных и 500 поддельных аккаунтов социальносй сети ВКонтакте был сделан ряд выводов об особенностях поддельных аккаунтов. Проведенное исследование позволило расширить список критериев идентификации поддельных аккаунтов набором шаблонов.

В статье~\cite{ChenW18} авторы нацеливаются на модель фиктивного аккаунта, который может не только автоматически публиковать сообщения или комментарии, но и рассылать рекламный спам или распространять ложную информацию. В этом исследовании был предложен метод обнаружения <<фейков>>. Он основан на шаблоне активности пользователя в Facebook с использованием машинного обучения, чтобы предсказать, контролируется ли учетная запись поддельным пользователем.

Работа~\cite{HsuKJ19} представляет результаты экспериментальной визуализации более 200 000 твитов из подтвержденных поддельных аккаунтов Twitter. Авторы анализируют учетные записи пользователей, изучая их имена пользователей, описания или биографии, твиты, их частоту и содержание. Исследователи обнаружили, что поддельные учетные записи узнаваемы благодаря политическим и религиозным убеждениям. Они присоединялись к популярным хэштегам в Twitter и публиковали твиты в критические моменты (например, во время дебатов).

Авторы статьи~\cite{FahmyAKE23} рассматривают влияние фиктивных аккаунтов на аккаунты людей. Цель работы – представить новую модель распространения информации. Исследователи вводят два типа пользователей с разным уровнем <<зараженности>>: пользователи, <<инфицированные>> человеком, и пользователи, <<зараженные>> учетными записями ботов. Было измерено влияние поддельных аккаунтов на скорость распространения лжи среди записей людей. Результаты эксперимента показывали, что точность предложенной модели превосходит классическую при моделировании процесса распространения слухов. Был сделан вывод, что <<фейки>> ускоряют процесс распространения невподтвержденной информации, поскольку они воздействуют на многих людей за короткое время.

\vspace{1.5em}
\subsection{Обзор основных методов, используемых для поиска аномалий}
\label{subsec:Variants}
Методы, которые могут использоваться для поиска аномалий:
\textbf{Isolation Forest} (изолированный лес)~\cite{LiuTZ08} представляет собой алгоритм обнаружения аномалий, который строит ансамбль изолирующих деревьев решений. В процессе построения этих деревьев, выбираются случайные признаки и случайные пороги для разбиения данных. Аномалии обычно требуют меньше разбиений, чтобы быть <<изолированными>> от остальных данных.

В основе метода лежит предположение, что аномальные точки будут находиться ближе к корню дерева, так как им потребуется меньше разбиений для выделения. Наоборот, нормальные точки должны быть более распределены по дереву. Путем измерения среднего пути до изоляции каждой точки, алгоритм может определить степень их аномальности.

\textbf{Hierarchical clustering} (иерархическая кластеризация)~\cite{clustering} – это алгоритм группировки данных, который строит иерархию кластеров. Существует два основных подхода: агломеративный и дивизивный.

Агломеративная кластеризация. Каждая точка рассматривается как отдельный кластер, на каждом шаге ближайшие кластеры объединяются в новый кластер. Может использоваться расстояние между кластерами (например, евклидово расстояние) или другие меры сходства. Повторяется до тех пор, пока все точки не объединятся в один кластер.
    
Дивизивная кластеризация. Вся выборка рассматривается как один кластер, на каждом шаге один из кластеров разбивается на более мелкие кластеры. Обычно используются меры несходства между подгруппами, такие как расстояние или сходство. Процесс повторяется до тех пор, пока каждая точка не станет отдельным кластером.
    
Результат иерархической кластеризации представляет собой дерево, называемое дендрограммой. Дендрограмма отображает последовательное объединение или разделение кластеров в зависимости от расстояний или мер сходства.

\textbf{DBSCAN} (Density-Based Spatial Clustering of Applications with Noise) ~\cite{dbscan} – это алгоритм кластеризации, который определяет кластеры на основе плотности данных в пространстве. Он может обнаруживать кластеры произвольной формы и выделять точки, не принадлежащие ни одному кластеру (шум).
    
DBSCAN обеспечивает гибкость в выявлении кластеров различной формы и эффективно обрабатывает точки, которые можно посчитать шумом. Однако на результат влияет выбор параметров: радиуса и минимального числа точек, которые должны образовывать плотную область.

Для оценки качества работы алгоритма будут использоваться метрики accuracy (аккуратность), precision (точность) и recall (полнота), F-measure (F-мера). Первая показывает долю верно классифицированных объектов, вторая – долю объектов, которые модель классифицировала как положительные, и которые действительно являются положительными, а третья – долю объектов положительного класса, которые модель определила правильно, четвертая - это комбинированная метрика, объединяющая точность и полноту в единственное число. 

Данные метрики можно вычислить по следующим формулам:


$$
accuracy = \frac{TP+TN}{TP+TN+FP+FN} = 0,63
$$

$$
precision = \frac{TP}{TP+FP} =  0,62
$$

$$
recall = \frac{TP+TN}{TP+FN} = 0,08
$$

$$
F\text{-}measure = 2\cdot \frac{precision \cdot recall}{precision+recall} = 0,14
$$

\vspace{1.5em}
Термины TP, TN, FP, FN используются в контексте матрицы ошибок (табл. ~\ref{tabular:tableMistakes}), которая является инструментом для оценки производительности моделей.

\begin{table}[!ht]
    \onehalfspacing \caption{Матрица ошибок}
    \medskip
    \begin{tabular}{c|cc}
        & \text{Positive} & \text{Negative} \\
        \hline
        \text{True} & \text{TP} & \text{TN} \\
        \text{False} & \text{FP} & \text{FN} \\
    \end{tabular}
    \label{tabular:tableMistakes}
\end{table}

TP (True Positives) – количество верно предсказанных положительных примеров. Это случаи, когда модель правильно предсказала, что объект принадлежит к положительному классу.

TN (True Negatives) – количество верно предсказанных отрицательных примеров. Это случаи, когда модель правильно предсказала, что объект принадлежит к отрицательному классу.

FP (False Positives) – количество ложно положительных примеров. Это случаи, когда модель ошибочно предсказала, что объект принадлежит к положительному классу, хотя на самом деле он принадлежит отрицательному классу.

FN (False Negatives) – количество ложно отрицательных примеров. Это случаи, когда модель ошибочно предсказала, что объект принадлежит отрицательному классу, хотя на самом деле он принадлежит положительному классу.
